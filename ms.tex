\documentclass[a4paper, 12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage[left=2cm, right=2cm, bottom=3cm, top=2cm]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{natbib}
\newcommand{\lbc}{\ell}


\title{lbrycred}
\author{Brendon J. Brewer}
\date{}

\begin{document}
\maketitle

%\abstract{\noindent Abstract}

% Need this after the abstract
\setlength{\parindent}{0pt}
\setlength{\parskip}{8pt}

Let $\boldsymbol{y} = \{y_1, y_2, ..., y_n\}$ be the vector of credibility
scores (where $y_i \geq 0$) and $\boldsymbol{w} = \left\{w_{ij}\right\}$
a matrix of signed supports, where
$w_{ij}$ is the support from channel $i$ to channel $j$. Let the diagonal
elements $w_{ii}$ include the bid, self supports, and anonymous supports.
In practice the $\boldsymbol{w}$ will be sparse and concentrated along the
diagonal. The total staked amount on channel $j$ is the column sum
\begin{align}
\ell_j = \sum_{i=1}^n w_{ij}.
\end{align}
It would be nice if $\boldsymbol{y}$ were in units of LBC and if
it was normalised to the same total as the staked LBC:
\begin{align}
\sum_{i=1}^n \ell_i = \sum_{i=1}^n y_i, \label{eqn:total_lbc}
\end{align}
and what I propose here and demonstrate in {\tt simulate.py} satisfies this
criterion.

We need to compute the $\boldsymbol{y}$ values from the $\boldsymbol{w}$,
and Jeremy (or someone else at LBRY Inc) proposed an iterative procedure which
reminds me of the
\href{https://en.wikipedia.org/wiki/Jacobi_method}{Jacobi Method} or
(more accurately) Gauss-Seidel. However,
I tried it out and it diverged --- presumably the matrix $\boldsymbol{w}$ had
eigenvalues above 1.

{\bf Aside mostly for my own thinking}:
One can think of these iterative methods as optimisation techniques; basically
Gibbs sampling at zero temperature in order to optimise some objective
function. Since I'm better at optimisation than linear algebra, I will try to
work in these terms. You can also think about these as numerical PDE solvers
like in undergrad COSC.


\section{Iterative Computation, Taking Supporter Credibility Into Account}
Now let's try replacing $\ell_j$ with an alternative that accounts for the
credibilities of the supporting channels. We'll need to treat the diagonal
value $w_{jj}$ differently because self and anonymous supports don't get
modified due to credibility.

To do this, I will introduce another quantity for each channel,
$\boldsymbol{m} = \{m_1, m_2, ..., m_n\}$. The {\em m} stands for
{\em multiplier}, as the effect of these is going to be multiplication of LBC
(so if a channel has $m=2$, their staked LBC is twice as valuable as someone
with $m=1$). All $m$ values are greater than or equal to 1.
Before continuing, let's define a nonlinear softening function which takes
an LBC amount as input and returns a multiplier value. Similar to trending,
I will use the fourth root, with a modification so that the initial value
is 1:
\begin{align}
\Phi(x) &= (x + 1)^{1/4}.
\end{align}
The inverse of this is
\begin{align}
\Phi^{-1}(x) &= x^4 - 1.
\end{align}

The convergence process will be performed for the $m$ values, and then,
once they have converged, used to recompute the $y$-values as follows:
\begin{align}
y_j &= w_{jj} + \sum_{i \neq j} m_i w_{ij}.
\end{align}
If all $m$s were 1, this would be equivalent to Equation~\ref{eqn:total_lbc}.



%I will also re-grade the credibility scores
%to be of order unity (but $\geq 1$), so they can be used as LBC multipliers.
%Let $\eta_j$ be the `effective' staked value on a channel, modified to account
%for the credibility of the supporters:
%\begin{align}
%\eta_j &= w_{jj} + \sum_{i \neq j} y_i w_{ij},
%\end{align}
%and let the objective function be
%\begin{align}
%f(\boldsymbol{y}) &= -\frac{1}{2}\sum_{i=1}^n \left[
%                            y_i - \Phi\left(w_{jj} + \sum_{i \neq j} y_i w_{ij}\right)
%                        \right]^2
%\end{align}
%where $\Phi()$ is a monotonic function mapping LBC units to something of order
%unity, and also satisfies $\Phi(0) = 1$. Let's try
%$\Phi(x) = \log_{10}(x + 10)$ and see what happens:
%\begin{align}
%f(\boldsymbol{y}) &= -\frac{1}{2}\sum_{i=1}^n \left[
%                            y_i - \log_{10}\left(10 + w_{jj} + \sum_{i \neq j} y_i w_{ij}\right)
%                        \right]^2 \\
%    &= -\frac{1}{2}\sum_{i=1}^n\left(y_i - \Phi(\eta_j)\right)^2 \\
%    &= -\frac{1}{2}\sum_{i=1}^n\left(y_i^2 - 2y_i\Phi(\eta_j) + \Phi(\eta_j)^2\right).
%\end{align}
%%Now take the partial derivative with respect to $y_k$:
%%\begin{align}
%%\frac{\partial f}{\partial y_k}
%%    &= -\frac{1}{2}\sum_{i=1}^n\left(y_i^2 - 2y_i\Phi(\eta_j) + \Phi(\eta_j)^2\right)
%%\end{align}
%A guessed iterative procedure to solve for the $y$s is to set each one to
%$\Phi(\eta)$ in turn. See {\tt simulate.py} in this repo.


\bibliographystyle{plainnat}
\bibliography{references}

\end{document}

